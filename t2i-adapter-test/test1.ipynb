{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu çalışmada T2I Adapter incelendi. T2I Adapter, ControlNet'e çok benzer. Aralarındaki farklara göz atalım. İlk olarak tek bir adapter kullanılarak, ardından multiadapter kullanılarak denemeler yapıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler \n",
    "from diffusers import T2IAdapter\n",
    "from diffusers import MultiAdapter\n",
    "from diffusers import StableDiffusionAdapterPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = T2IAdapter.from_pretrained(\"TencentARC/t2iadapter_color_sd14v1\")\n",
    "\n",
    "pipe_t2i = StableDiffusionAdapterPipeline.from_pretrained(\"/home/sd_models/deliberate_v2/\", adapter=adapter)\n",
    "pipe_t2i.scheduler = DPMSolverMultistepScheduler.from_config(pipe_t2i.scheduler.config)\n",
    "pipe_t2i.to(\"cuda\", torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(\"../media/input_images/167.png\")\n",
    "color_image = Image.open(\"../media/input_images/color.png\")\n",
    "depth_image = Image.open(\"../media/input_images/depth.png\")\n",
    "\n",
    "fig,ax = plt.subplots(1,3, figsize=(15,5))\n",
    "ax[0].title.set_text(\"Input Image\")\n",
    "ax[0].imshow(input_image)\n",
    "ax[1].title.set_text(\"Color Image\")\n",
    "ax[1].imshow(color_image)\n",
    "ax[2].title.set_text(\"Depth Image\")\n",
    "ax[2].imshow(depth_image, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_divisible(img, divisor=8):\n",
    "    return img.resize((img.width // divisor * divisor, img.height // divisor * divisor))\n",
    "\n",
    "color_image = resize_divisible(color_image)\n",
    "depth_image = resize_divisible(depth_image)\n",
    "print(color_image.width, color_image.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = pipe_t2i(\n",
    "    prompt = \"red and pink flowers with green leaves\",\n",
    "    image=color_image,\n",
    "    height=color_image.height,\n",
    "    width=color_image.width,\n",
    "    num_inference_steps=25,\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ").images[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].title.set_text(\"Input Image\")\n",
    "ax[0].imshow(color_image)\n",
    "ax[1].title.set_text(\"Output Image\")\n",
    "ax[1].imshow(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "cond_color = color_image.resize((512, 512))\n",
    "cond_depth = depth_image.resize((512, 512)).convert(\"RGB\")\n",
    "print(cond_color.size, cond_color.mode)\n",
    "print(cond_depth.size, cond_depth.mode)\n",
    "cond = [cond_color, cond_depth]\n",
    "\n",
    "prompt = [\"pink and red flowers with green leaves, a beautiful flower with green leaves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters = MultiAdapter(\n",
    "    [\n",
    "        T2IAdapter.from_pretrained(\"TencentARC/t2iadapter_color_sd14v1\"),\n",
    "        T2IAdapter.from_pretrained(\"TencentARC/t2iadapter_depth_sd14v1\"),\n",
    "    ]\n",
    ")\n",
    "adapters = adapters.to(torch.float16)\n",
    "\n",
    "pipe = StableDiffusionAdapterPipeline.from_pretrained(\n",
    "    \"/home/sd_models/deliberate_v2/\",\n",
    "    torch_dtype=torch.float16,\n",
    "    adapter=adapters,\n",
    ").to(\"cuda\")\n",
    "\n",
    "image = pipe(prompt, \n",
    "             cond, \n",
    "             width=512, \n",
    "             height=512, \n",
    "             adapter_conditioning_scale=[0.8, 0.8]).images[0]\n",
    "\n",
    "make_image_grid([cond_color, cond_depth, image], rows=1, cols=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
