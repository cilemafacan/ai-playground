{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP Guided Stable Diffusion Community Sample\n",
    "Test edildi. Kisa denemelerde yararli bir fark gorulmedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusers path: f:\\dev\\aitnew\\diffusers\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------------#\n",
    "# Add diffusers path to sys path\n",
    "import sys\n",
    "import os\n",
    "# Get Diffusers path from environment variable\n",
    "diffusers_path = os.getenv('DIFFUSERS_PATH')\n",
    "print(f\"Diffusers path: {diffusers_path}\")\n",
    "if diffusers_path is None:\n",
    "    raise ValueError(\"Please set DIFFUSERS_PATH environment variable to Diffusers path\")\n",
    "sys.path.append(diffusers_path+\"/src\")\n",
    "#----------------------------------------------------------------------------------------#\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "models = [r'f:\\sd_models\\ghostmix_v2',\n",
    "          r'f:\\sd_models\\aesteticmix',\n",
    "          r'f:\\sd_models\\revAnimated_v122',]\n",
    "device = \"cuda\"\n",
    "\n",
    "# print pytorch version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8af41cea484a01930fbc7dc8b0d640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(models[1], safety_checker=None)\n",
    "pipe = pipe.to(device, torch.float16)\n",
    "\n",
    "prompt = \"Flower design pattern with watercolor background (sharp, crisp, masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), extreme detailed,colorful,highest detailed:1.3\"\n",
    "prompt2 = \"fantasy book cover, full moon, fantasy forest landscape, golden vector elements, fantasy magic, dark light night, intricate, elegant, sharp focus, illustration, highly detailed, digital painting, concept art, matte, art by WLOP and Artgerm and Albert Bierstadt, masterpiece\"\n",
    "negative_prompt = \"(worst quality, low quality:2), monochrome, zombie,overexposure, watermark,text,bad anatomy,bad hand,extra hands,extra fingers,too many fingers,fused fingers,bad arm,distorted arm,extra arms,fused arms,extra legs,missing leg,disembodied leg,extra nipples, detached arm, liquid hand,inverted hand,disembodied limb, small breasts, loli, oversized head,extra body,completely nude, extra navel,easynegative,(hair between eyes),sketch, duplicate, ugly, huge eyes, text, logo, worst face, (bad and mutated hands:1.3),  (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), ((2girl)), (deformed fingers:1.2), (long fingers:1.2),(bad-artist-anime), bad-artist, bad hand, extra legs ,(ng_deepnegative_v1_75t)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a28aa056609442c8f7c8813db887dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = torch.Generator(device=\"cuda\").manual_seed(2)\n",
    "image = pipe(\n",
    "            prompt\n",
    "            ,num_inference_steps = 50\n",
    "            ,height = 512\n",
    "            ,width = 512\n",
    "            , guidance_scale = 6\n",
    "            #, negative_prompt = negative_prompt\n",
    "            , generator = generator\n",
    "            ).images[0]\n",
    "# save the image\n",
    "image.save('./test1_out/normal_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26cd20c802b405ba6644a64d5ca1701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810f6101ef0349c28afb363d8a9884a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import CLIPImageProcessor, CLIPModel\n",
    "feature_extractor = CLIPImageProcessor.from_pretrained(\"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\")\n",
    "clip_model = CLIPModel.from_pretrained(\"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\", torch_dtype=torch.float16)\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(2)\n",
    "\n",
    "guided_pipeline = DiffusionPipeline.from_pretrained(\n",
    "    models[1],\n",
    "    custom_pipeline=\"clip_guided_stable_diffusion\",\n",
    "    clip_model=clip_model,\n",
    "    feature_extractor=feature_extractor,    \n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "guided_pipeline.enable_attention_slicing()\n",
    "guided_pipeline = guided_pipeline.to(\"cuda\")\n",
    "\n",
    "image = guided_pipeline(\n",
    "    prompt,    \n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=7.5,\n",
    "    clip_guidance_scale=6,\n",
    "    num_cutouts=4,\n",
    "    use_cutouts=False,\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "image.save(\"./test1_out/guided_image.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
