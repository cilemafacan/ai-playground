{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from einops import repeat\n",
    "from omegaconf import OmegaConf\n",
    "from ldm.util import instantiate_from_config\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = \"inputs\"\n",
    "outdir = \"outputs\"\n",
    "steps = 30\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_sd(image, mask, txt, device, num_samples=1):\n",
    "    \n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "    image = image[None].transpose(0,3,1,2)\n",
    "    image = torch.from_numpy(image).to(dtype=torch.float32)/127.5-1.0\n",
    "\n",
    "    mask = np.array(mask.convert(\"L\"))\n",
    "    mask = mask.astype(np.float32)/255.0\n",
    "    mask = mask[None,None]\n",
    "    mask[mask < 0.5] = 0\n",
    "    mask[mask >= 0.5] = 1\n",
    "    mask = torch.from_numpy(mask)\n",
    "\n",
    "    masked_image = image * (mask < 0.5)\n",
    "\n",
    "    batch = {\n",
    "            \"image\": repeat(image.to(device=device), \"1 ... -> n ...\", n=num_samples),\n",
    "            \"txt\": num_samples * [txt],\n",
    "            \"mask\": repeat(mask.to(device=device), \"1 ... -> n ...\", n=num_samples),\n",
    "            \"masked_image\": repeat(masked_image.to(device=device), \"1 ... -> n ...\", n=num_samples),\n",
    "            }\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = sorted(glob.glob(os.path.join(indir, \"*_mask.png\")))\n",
    "images = [x.replace(\"_mask.png\", \".png\") for x in masks]\n",
    "print(f\"Found {len(masks)} inputs.\")\n",
    "\n",
    "config = OmegaConf.load(\"models/ldm/inpainting_big/config.yaml\")\n",
    "model = instantiate_from_config(config.model)\n",
    "model.load_state_dict(torch.load(\"models/ldm/inpainting_big/sd-v1-5-inpainting.ckpt\")[\"state_dict\"],\n",
    "                        strict=False)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "sampler = DDIMSampler(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint(sampler, image, mask, prompt, seed, scale, ddim_steps, num_samples=1, w=512, h=512):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model = sampler.model\n",
    "\n",
    "    prng = np.random.RandomState(seed)\n",
    "    start_code = prng.randn(num_samples, 4, h//8, w//8)\n",
    "    start_code = torch.from_numpy(start_code).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            batch = make_batch_sd(image, mask, txt=prompt, device=device, num_samples=num_samples)\n",
    "\n",
    "            c = model.cond_stage_model.encode(batch[\"txt\"])\n",
    "\n",
    "            c_cat = list()\n",
    "            for ck in model.concat_keys:\n",
    "                cc = batch[ck].float()\n",
    "                if ck != model.masked_image_key:\n",
    "                    bchw = [num_samples, 4, h//8, w//8]\n",
    "                    cc = torch.nn.functional.interpolate(cc, size=bchw[-2:])\n",
    "                else:\n",
    "                    cc = model.get_first_stage_encoding(model.encode_first_stage(cc))\n",
    "                c_cat.append(cc)\n",
    "            c_cat = torch.cat(c_cat, dim=1)\n",
    "\n",
    "            # cond\n",
    "            cond={\"c_concat\": [c_cat], \"c_crossattn\": [c]}\n",
    "\n",
    "            # uncond cond\n",
    "            uc_cross = model.get_unconditional_conditioning(num_samples, \"\")\n",
    "            uc_full = {\"c_concat\": [c_cat], \"c_crossattn\": [uc_cross]}\n",
    "\n",
    "            shape = [model.channels, h//8, w//8]\n",
    "            samples_cfg, _ = sampler.sample(\n",
    "                    ddim_steps,\n",
    "                    num_samples,\n",
    "                    shape,\n",
    "                    cond,\n",
    "                    verbose=False,\n",
    "                    eta=1.0,\n",
    "                    unconditional_guidance_scale=scale,\n",
    "                    unconditional_conditioning=uc_full,\n",
    "                    x_T=start_code,\n",
    "            )\n",
    "            x_samples_ddim = model.decode_first_stage(samples_cfg)\n",
    "\n",
    "            result = torch.clamp((x_samples_ddim+1.0)/2.0,\n",
    "                                 min=0.0, max=1.0)\n",
    "\n",
    "            result = result.cpu().numpy().transpose(0,2,3,1)\n",
    "            result = result*255\n",
    "\n",
    "    result = [Image.fromarray(img.astype(np.uint8)) for img in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"inputs/1.png\")\n",
    "mask = Image.open(\"inputs/1_mask.png\")\n",
    "prompt = \"a flower dress wearing a woman√ü\"\n",
    "seed = 0\n",
    "scale = 10\n",
    "ddim_steps = 30\n",
    "num_samples = 1\n",
    "w = 512\n",
    "h = 512\n",
    "\n",
    "result = inpaint(sampler, image, mask, prompt, seed, scale, ddim_steps, num_samples, w, h)\n",
    "result[0].save(\"outputs/1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (main, May 15 2023, 15:45:52) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ee4627a4c17c358e454dc07642658678ac6884506485624e3220e6043f82dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
