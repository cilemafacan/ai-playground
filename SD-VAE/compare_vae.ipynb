{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "up_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(current_dir)\n",
    "sys.path.append(up_dir)\n",
    "from common_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1_5 = AutoencoderKL.from_pretrained(\"AITSIS/imagine-v1\", subfolder=\"vae\", torch_type=torch.float16)\n",
    "pipe_1_5.to(\"cuda:0\", torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_xl = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\",  torch_type=torch.float16)\n",
    "pipe_xl.to(\"cuda:1\", torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1_5_base = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\", torch_type=torch.float16)\n",
    "pipe_1_5_base.to(\"cuda:2\", torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"../../media/training_images/100_lora paisey_1024/19-5539.png\").convert(\"RGB\")\n",
    "transformed_image = torchvision.transforms.ToTensor()(image).unsqueeze(0) * 2 - 1\n",
    "#transformed_image = transformed_image.to(\"cuda:1\", torch.float16)\n",
    "print(transformed_image.shape)\n",
    "print(transformed_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs  = []\n",
    "output_1_5 = pipe_1_5(transformed_image.to(\"cuda:0\", torch.float16))\n",
    "output_xl = pipe_xl(transformed_image.to(\"cuda:1\", torch.float16))\n",
    "output_1_5_base = pipe_1_5_base(transformed_image.to(\"cuda:2\", torch.float16))\n",
    "outputs.append({\"imagine\": output_1_5.sample,\n",
    "                \"output_xl\": output_xl.sample,\n",
    "                \"output_1_5_base\": output_1_5_base.sample})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i, output in enumerate(outputs):\n",
    "    for key, value in output.items():\n",
    "        out_image = (value / 2 + 0.5).clamp(0,1).squeeze(0)\n",
    "        out_image =  out_image.detach().cpu().permute(1,2,0).numpy()  \n",
    "        out_image = (out_image * 255).round().astype(\"uint8\") \n",
    "        out_pil = Image.fromarray(out_image)\n",
    "\n",
    "        out_pil.save(f\"../../media/outputs/{key}.png\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
