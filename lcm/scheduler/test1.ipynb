{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samplers veya Schedulers\n",
    "\n",
    "Sampler, bir görüntüye yinelemeli olarak gürültü eklemek veya model çıktısına dayalı olarak bir örneği güncellemek için kullanılır.\n",
    "\n",
    "* Bu tutorial'da aşağıdaki smapler örnekleri incelenecek ve farklarına bakılacak:\n",
    "\n",
    "    1) ddim\n",
    "    2) ddpm\n",
    "    3) eular\n",
    "    4) euler_ancestral\n",
    "    5) pndm\n",
    "    6) stochastic_karras_ve\n",
    "    7) ipndm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------#\n",
    "# Add diffusers path to sys path\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv;\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "# Get Diffusers path from environment variable\n",
    "diffusers_path = os.getenv('DIFFUSERS_PATH')\n",
    "print(f\"Diffusers path: {diffusers_path}\")\n",
    "if diffusers_path is None:\n",
    "    raise ValueError(\"Please set DIFFUSERS_PATH environment variable to Diffusers path\")\n",
    "sys.path.append(diffusers_path+\"/src\")\n",
    "#----------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "from diffusers import DiffusionPipeline, StableDiffusionImg2ImgPipeline, AutoPipelineForImage2Image\n",
    "from diffusers import DDIMScheduler\n",
    "from diffusers import DDIMInverseScheduler\n",
    "from diffusers import DEISMultistepScheduler\n",
    "from diffusers import KDPM2AncestralDiscreteScheduler\n",
    "from diffusers import KDPM2DiscreteScheduler\n",
    "\n",
    "from diffusers import DDPMScheduler\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import EulerAncestralDiscreteScheduler\n",
    "from diffusers import PNDMScheduler\n",
    "from diffusers import HeunDiscreteScheduler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"fruits\"\n",
    "steps = 20\n",
    "strength = 0.6\n",
    "guidance_scale = 0\n",
    "generator = torch.Generator(device='cuda').manual_seed(8)\n",
    "adapter_id = \"latent-consistency/lcm-lora-sdv1-5\"\n",
    "\n",
    "input = PIL.Image.open(\"../../media/input_images/1041.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = AutoPipelineForImage2Image.from_pretrained(\"/home/sd_models/deliberate_v2/\", safety_checker=None)\n",
    "pipe.to(\"cuda\", torch.float16)\n",
    "print(pipe.scheduler)\n",
    "pipe.load_lora_weights(adapter_id)\n",
    "pipe.fuse_lora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_list = [\n",
    "    DDIMScheduler,\n",
    "    DEISMultistepScheduler,\n",
    "    KDPM2AncestralDiscreteScheduler,\n",
    "    KDPM2DiscreteScheduler,\n",
    "    DDPMScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    PNDMScheduler,\n",
    "    HeunDiscreteScheduler\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "outputs.append({\"name\": \"input\", \"image\": input})\n",
    "for sch in sch_list:\n",
    "    pipe.scheduler = sch.from_config(pipe.scheduler.config)\n",
    "    generator = torch.Generator(device='cuda').manual_seed(48)\n",
    "    image = pipe(image = input, prompt=prompt, num_inference_steps=steps, generator=generator, strength=strength, guidance_scale=guidance_scale).images[0]\n",
    "    print(sch.__name__)\n",
    "    outputs.append({\"name\": sch.__name__, \"image\": image})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib grid\n",
    "fig, axs = plt.subplots(5, 2, figsize=(15, 40))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(outputs[i][\"image\"])\n",
    "    ax.set_title(outputs[i][\"name\"])\n",
    "    # info text\n",
    "    ax.axis('off')\n",
    "ax.text(0.5,-0.5, f\"steps: {steps}\\nstrength: {strength}\\nguidance_scale: {guidance_scale}\\nprompt: {prompt}\", size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
