{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers import StableDiffusion3Img2ImgPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "from diffusers import EulerAncestralDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../1_media/input_images/cat.jpg\"\n",
    "strength = 0.35\n",
    "guidance_scale = 15\n",
    "num_inference_steps = 50\n",
    "init_image = Image.open(image_dir).convert(\"RGB\")\n",
    "prompt = \"a cat\"\n",
    "negative_prompt = \"lowres, extra digit, fewer digits, cropped, worst quality, low quality, text, word, icon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.splitext(os.path.basename(image_dir))[0]\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Deliberate\n",
    "Scheduler : DPMSolverMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = StableDiffusionImg2ImgPipeline.from_pretrained(\"Yntec/Deliberate2\", torch_dtype=torch.float16)\n",
    "pipe1.scheduler = DPMSolverMultistepScheduler.from_config(pipe1.scheduler.config)\n",
    "pipe1 = pipe1.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe1(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt).images[0]\n",
    "\n",
    "output.save(f\"{output_dir}/deliberate_dpm.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Deliberate\n",
    "Scheduler : EulerAncestralDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe1.scheduler.config)\n",
    "pipe1 = pipe1.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = pipe1(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt).images[0]\n",
    "\n",
    "output2.save(f\"{output_dir}/deliberate_eulera.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Realistic Vision 6\n",
    "Scheduler : DPMSolverMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = StableDiffusionImg2ImgPipeline.from_pretrained(\"SG161222/Realistic_Vision_V6.0_B1_noVAE\", torch_dtype=torch.float16)\n",
    "pipe2.scheduler = DPMSolverMultistepScheduler.from_config(pipe2.scheduler.config)\n",
    "pipe2 = pipe2.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = pipe2(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt).images[0]\n",
    "\n",
    "output3.save(f\"{output_dir}/rvision_dpm.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Realistic Vision 6\n",
    "Scheduler : EulerAncestralDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe2.scheduler.config)\n",
    "pipe2 = pipe2.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output4 = pipe2(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt).images[0]\n",
    "\n",
    "output4.save(f\"{output_dir}/rvision_eulera.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Deliberate\n",
    "Scheduler : DPMSolverMultistepScheduler\n",
    "Lora : LCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = StableDiffusionImg2ImgPipeline.from_pretrained(\"Yntec/Deliberate2\", torch_dtype=torch.float16)\n",
    "pipe3.scheduler = DPMSolverMultistepScheduler.from_config(pipe3.scheduler.config)\n",
    "pipe3 = pipe3.to(\"cuda:0\")\n",
    "\n",
    "pipe3.load_lora_weights(\"latent-consistency/lcm-lora-sdv1-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output5 = pipe3(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=1,\n",
    "                num_inference_steps=4).images[0]\n",
    "\n",
    "output5.save(f\"{output_dir}/deliberate_dpm_lcm.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Deliberate\n",
    "Scheduler : EulerAncestralDiscreteScheduler\n",
    "Lora : LCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe3.scheduler.config)\n",
    "pipe3 = pipe3.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output6 = pipe3(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=1,\n",
    "                num_inference_steps=4).images[0]\n",
    "\n",
    "output6.save(f\"{output_dir}/deliberate_eulera_lcm.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : stabilityai/stable-diffusion-xl-base-1.0\n",
    "Scheduler : DPMSolverMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16)\n",
    "pipe5.scheduler = DPMSolverMultistepScheduler.from_config(pipe5.scheduler.config)\n",
    "pipe5 = pipe5.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output9 = pipe5(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=init_image.width,\n",
    "                height=init_image.height).images[0]\n",
    "\n",
    "output9.save(f\"{output_dir}/sdxl_dpm.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : stabilityai/stable-diffusion-xl-base-1.0\n",
    "Scheduler : EulerAncestralDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe5.scheduler.config)\n",
    "pipe5 = pipe5.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output10 = pipe5(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=init_image.width,\n",
    "                height=init_image.height).images[0]\n",
    "\n",
    "output10.save(f\"{output_dir}/sdxl_eulera.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Playground V2\n",
    "Scheduler : DPMSolverMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6 = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"playgroundai/playground-v2-1024px-aesthetic\", torch_dtype=torch.float16,variant=\"fp16\")\n",
    "pipe6.scheduler = DPMSolverMultistepScheduler.from_config(pipe6.scheduler.config)\n",
    "pipe6 = pipe6.to(\"cuda:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output11 = pipe6(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=init_image.width,\n",
    "                height=init_image.height).images[0]\n",
    "\n",
    "output11.save(f\"{output_dir}/playgroundv2_dpm.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : Playground V2\n",
    "Scheduler : EulerAncestralDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe6.scheduler.config)\n",
    "pipe6 = pipe6.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output12 = pipe6(image=init_image,\n",
    "                prompt=prompt,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=init_image.width,\n",
    "                height=init_image.height).images[0]\n",
    "\n",
    "output12.save(f\"{output_dir}/playgroundv2_eulera.png\")\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
